{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b22eab9-1c03-4c1f-93cb-e97881753454",
   "metadata": {},
   "source": [
    "# Testing the trained flow\n",
    "\n",
    "Once the Normalising Flow was trained using `train.py`, it can be used for inversion. This is a tutorial on how to generate results from some synthetic test data.\n",
    "\n",
    "First, we need to read in the flow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4f760f-1716-41fa-be25-846056be6147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained_flow\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'trained_flow/flow.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# defining the GPU\u001b[39;00m\n\u001b[1;32m      8\u001b[0m flow \u001b[38;5;241m=\u001b[39m FlowModel()\n\u001b[0;32m----> 9\u001b[0m flow\u001b[38;5;241m.\u001b[39mload(flow_location)\n\u001b[1;32m     10\u001b[0m flow\u001b[38;5;241m.\u001b[39mflowmodel\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m flow\u001b[38;5;241m.\u001b[39msave_location \u001b[38;5;241m=\u001b[39m flow_location\n",
      "File \u001b[0;32m~/Desktop/flowinv/giflow/flowmodel.py:110\u001b[0m, in \u001b[0;36mFlowModel.load\u001b[0;34m(self, location, device)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(key, attr[key])\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstruct()\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflowmodel\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(location, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflow.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflowmodel\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flowenv/lib/python3.12/site-packages/torch/serialization.py:997\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    995\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 997\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    999\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flowenv/lib/python3.12/site-packages/torch/serialization.py:444\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/flowenv/lib/python3.12/site-packages/torch/serialization.py:425\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'trained_flow/flow.pt'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from giflow.flowmodel import FlowModel\n",
    "\n",
    "flow_location = 'trained_flow'\n",
    "\n",
    "device = torch.device('cuda') # defining the GPU\n",
    "\n",
    "flow = FlowModel()\n",
    "flow.load(flow_location)\n",
    "flow.flowmodel.to(device)\n",
    "flow.save_location = flow_location\n",
    "data = flow.data_location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b0c2a8-2b49-4435-835b-6f756a5277c0",
   "metadata": {},
   "source": [
    "Need to load in data that we want to test the network with. In this case we are using the validation data to conduct a P-P test. We need to ensure that the data set that we are testing on has the same parameters as the training data, eg. the same `survey_coordinates_to_include` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8490970-3275-43b7-9ce9-16d881c2f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data\n",
    "valsize = 500 \n",
    "with open(os.path.join(data, 'valset.pkl'), 'rb') as file:\n",
    "    dt_val = pkl.load(file)\n",
    "    validation_data, validation_conditional = dt_val.make_data_for_network(\n",
    "        survey_coordinates_to_include = ['noise_scale'],\n",
    "        model_info_to_include = [],\n",
    "        add_noise = True,\n",
    "        mix_survey_order = False,\n",
    "    )\n",
    "validation_dataset = flow.make_tensor_dataset(validation_data, validation_conditional, device=device, scale=True)\n",
    "\n",
    "# Test data\n",
    "testsize = 2\n",
    "with open(os.path.join(data, 'testset.pkl'), 'rb') as file:\n",
    "    dt_test = pkl.load(file)\n",
    "    test_data, test_conditional = dt_test.make_data_for_network(\n",
    "        survey_coordinates_to_include = ['noise_scale'],\n",
    "        model_info_to_include = [],\n",
    "        add_noise = True,\n",
    "        mix_survey_order = False,\n",
    "    )\n",
    "test_dataset = flow.make_tensor_dataset(test_data, test_conditional, device=device, scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538fca82-a38c-4179-8e71-ed4a38c96e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conducting a P-P test, where diagonal lines indicate statistical consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e441d6d-a1e3-441c-bcad-5b8358db93d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P-P plot\n",
    "flow.pp_test(validation_dataset=validation_dataset,\n",
    "             parameter_labels=dt_val.parameter_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66edf716-c094-4495-bea9-d70a0a6e6a6d",
   "metadata": {},
   "source": [
    "Now, we want to generate some inversion results from some test data. For this, we need to sample the flow and construct `FlowResults` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b8a95c-a7ff-40f1-a675-dfee8fd4f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating results for some test data\n",
    "results = []\n",
    "for i in range(testsize):\n",
    "    samples, log_probabilities = flow.sample_and_logprob(test_dataset.tensors[1][i], # the conditional\n",
    "                                                         num=2000) # number of samples we want to draw\n",
    "    result = BoxFlowResults(samples=samples,\n",
    "                            conditional=[test_conditional[j][i] for j in range(len(test_conditional))],\n",
    "                            log_probabilities=log_probabilities,\n",
    "                            true_parameters=np.array([test_data[0][i]]),\n",
    "                            parameter_labels=dt_val.parameter_labels,\n",
    "                            survey_coordinates=dt_test.surveys[0].survey_coordinates\n",
    "                           )\n",
    "    results.append(result)\n",
    "    result.directory = os.path.join(flow_location, f\"testcase_{i}/\")\n",
    "    \n",
    "    # plotting the surveys we are inverting\n",
    "    dt_test.surveys[i].plot_contours(filename=os.path.join(result.directory, \"survey.png\"),\n",
    "                                     include_noise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a325cf87-f708-4c34-b6c6-8b6ebd1be88d",
   "metadata": {},
   "source": [
    "To make corner plots of the posterior probability distribution, we can use the `corner_plot()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09767783-5f4a-4b3e-89cb-712fda34ea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, result in enumerate(results):\n",
    "    result.corner_plot(filename=\"corner_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837fba66-5a6f-4ce6-a11d-797fb0dd9337",
   "metadata": {},
   "source": [
    "To make voxelised plots from parameterised data, first we need to define what grid we want to translate our data to. Then, we can use the `plot_compare_voxel_slices()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164a5097-1f10-438d-8d20-7544a6c738dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_test.model_framework['ranges'] = [[-0.75, 0.75], [-0.75, 0.75], [-1.5, 0.0]]\n",
    "dt_test.model_framework['grid_shape'] = [10, 10, 10]\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    result.plot_compare_voxel_slices(filename=f\"compare_voxel_slices.png\",\n",
    "                                     plot_truth=True,\n",
    "                                     normalisation=[-2500.0, 500.0],\n",
    "                                     model_framework=dt_test.model_framework,\n",
    "                                     slice_coords=[1, 4, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ced932c-03d2-4201-8f2a-c8dde1370cf7",
   "metadata": {},
   "source": [
    "There are many other testing and plotting functionalities built into the `FlowResults` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539c7dd1-39f1-4849-8143-03817be151bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
